# backend/services/evaluation_service.py

import os
import json
import faiss
import numpy as np
from langchain_google_genai import GoogleGenerativeAIEmbeddings # Google ì„ë² ë”© ëª¨ë¸ ì‚¬ìš©
from core.config import GOOGLE_API_KEY

# --- ì„œë¹„ìŠ¤ ì´ˆê¸°í™”: ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ ì‹¤í–‰ë˜ë„ë¡ ---

# 1. ë°ì´í„° ê²½ë¡œ ì„¤ì •
# ëª¨ë¸ í´ë”ì—ì„œ ë³µì‚¬í•´ì˜¨ ì‹¤ì œ ë°ì´í„° ê²½ë¡œì…ë‹ˆë‹¤.
FAISS_INDEX_PATH = "/app/data/passages.faiss"  # ì‹¤ì œ FAISS ì¸ë±ìŠ¤ íŒŒì¼
METADATA_PATH = "/app/data/meta.json"          # ë©”íƒ€ë°ì´í„° JSON íŒŒì¼

# ë˜ëŠ” í˜„ì¬ íŒŒì¼ ê¸°ì¤€ ìƒëŒ€ê²½ë¡œ (ë” ì•ˆì „í•œ ë°©ë²•)
def get_data_path():
    """í˜„ì¬ íŒŒì¼ ìœ„ì¹˜ ê¸°ì¤€ìœ¼ë¡œ data ë””ë ‰í† ë¦¬ ê²½ë¡œ ë°˜í™˜"""
    current_dir = os.path.dirname(os.path.abspath(__file__))
    # /app/services/evaluation_service.py -> /app/data
    return os.path.join(os.path.dirname(current_dir), "data")

DATA_DIR = get_data_path()
FAISS_INDEX_PATH_ALT = os.path.join(DATA_DIR, "passages.faiss")
METADATA_PATH_ALT = os.path.join(DATA_DIR, "meta.json")

# 2. ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
# Google ê¸°ë°˜ìœ¼ë¡œ í†µì¼í•˜ì—¬ ì‚¬ìš©í•©ë‹ˆë‹¤.
embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001", google_api_key=GOOGLE_API_KEY)

# 3. ì „ì—­ ë³€ìˆ˜ ì´ˆê¸°í™”
faiss_index = None
metadata_list = None

# 4. FAISS Vector DBì™€ ë©”íƒ€ë°ì´í„° ì§ì ‘ ë¡œë“œ
# PKL íŒŒì¼ ì—†ì´ FAISS ì¸ë±ìŠ¤ì™€ ë©”íƒ€ë°ì´í„°ë¥¼ ê°ê° ë¡œë“œí•©ë‹ˆë‹¤.
def load_faiss_index_and_metadata():
    """FAISS ì¸ë±ìŠ¤ì™€ ë©”íƒ€ë°ì´í„°ë¥¼ ì§ì ‘ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜"""
    global faiss_index, metadata_list
    
    # ì—¬ëŸ¬ ê²½ë¡œ ì‹œë„
    possible_paths = [
        ("/app/data/passages.faiss", "/app/data/meta.json"),
        (FAISS_INDEX_PATH_ALT, METADATA_PATH_ALT),
        ("backend/data/passages.faiss", "backend/data/meta.json"),
        ("data/passages.faiss", "data/meta.json")
    ]
    
    print("ğŸ” FAISS ì¸ë±ìŠ¤ íŒŒì¼ ê²½ë¡œ íƒìƒ‰ ì¤‘...")
    
    for faiss_path, meta_path in possible_paths:
        print(f"   ì‹œë„ ì¤‘: {faiss_path}")
        
        if os.path.exists(faiss_path) and os.path.exists(meta_path):
            try:
                # FAISS ì¸ë±ìŠ¤ ë¡œë“œ
                faiss_index = faiss.read_index(faiss_path)
                
                # ë©”íƒ€ë°ì´í„° ë¡œë“œ
                with open(meta_path, "r", encoding="utf-8") as f:
                    metadata_list = json.load(f)
                
                print(f"âœ… FAISS ì¸ë±ìŠ¤ ë¡œë“œ ì„±ê³µ: {faiss_index.ntotal}ê°œ ë²¡í„°")
                print(f"âœ… ë©”íƒ€ë°ì´í„° ë¡œë“œ ì„±ê³µ: {len(metadata_list)}ê°œ ë¬¸ì„œ")
                print(f"ğŸ“ ì‚¬ìš©ëœ ê²½ë¡œ: {faiss_path}")
                print("âœ… FAISS Vector DB ì´ˆê¸°í™” ì™„ë£Œ - ê²€ìƒ‰ ì„œë¹„ìŠ¤ ì¤€ë¹„ë¨")
                
                return  # ì„±ê³µí•˜ë©´ í•¨ìˆ˜ ì¢…ë£Œ
                
            except Exception as e:
                print(f"âŒ íŒŒì¼ì€ ì¡´ì¬í•˜ì§€ë§Œ ë¡œë“œ ì‹¤íŒ¨: {e}")
                continue
        else:
            print(f"   âŒ íŒŒì¼ ì—†ìŒ")
    
    # ëª¨ë“  ê²½ë¡œ ì‹¤íŒ¨
    print("âŒ ëª¨ë“  ê²½ë¡œì—ì„œ FAISS ì¸ë±ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print("âš ï¸ FAISS ë˜ëŠ” ë©”íƒ€ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ - ê¸°ë³¸ í•´ì„¤ ëª¨ë“œë¡œ ë™ì‘")
    faiss_index, metadata_list = None, None

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ ì¸ë±ìŠ¤ ë¡œë“œ ì‹¤í–‰
load_faiss_index_and_metadata()

# --- ì‹¤ì œ ì„œë¹„ìŠ¤ í•¨ìˆ˜ ---

async def get_relevant_passage(query: str) -> str:
    """
    ì‚¬ìš©ìì˜ ì§ˆë¬¸(query)ê³¼ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ì§€ë¬¸ ë‚´ìš©ì„ Vector DBì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    PKL íŒŒì¼ ì—†ì´ ì§ì ‘ FAISS ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    
    Args:
        query (str): ì‚¬ìš©ìì˜ ì§ˆë¬¸ ë˜ëŠ” ê²€ìƒ‰ì–´
        
    Returns:
        str: ê²€ìƒ‰ëœ ê´€ë ¨ ì§€ë¬¸ ë‚´ìš© ë˜ëŠ” ê¸°ë³¸ ë©”ì‹œì§€
    """
    
    # Vector DB ë¡œë“œ ìƒíƒœ í™•ì¸
    if faiss_index is None or metadata_list is None:
        return """
        Vector DBê°€ ë¡œë“œë˜ì§€ ì•Šì•„ ê¸°ë³¸ í•´ì„¤ì„ ì œê³µí•©ë‹ˆë‹¤.
        
        ìˆ˜ëŠ¥ êµ­ì–´ ë¹„ë¬¸í•™ ë¬¸ì œ í•´ì„¤:
        í•™ìƒì˜ ë‹µë³€ì„ ì¢…í•©ì ìœ¼ë¡œ í‰ê°€í•˜ì—¬ ì •í™•í•œ í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤.
        ì§€ë¬¸ì˜ í•µì‹¬ ë‚´ìš©ê³¼ ë…¼ë¦¬ì  ì¶”ë¡  ê³¼ì •ì„ ì¤‘ì‹¬ìœ¼ë¡œ í‰ê°€í•©ë‹ˆë‹¤.
        """
    
    try:
        # 1. ì¿¼ë¦¬ë¥¼ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜
        query_vector = embeddings.embed_query(query)
        query_array = np.array([query_vector], dtype=np.float32)
        
        # 2. FAISSë¥¼ ì‚¬ìš©í•˜ì—¬ ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰ (ìƒìœ„ 3ê°œ)
        k = 3  # ê²€ìƒ‰í•  ë¬¸ì„œ ê°œìˆ˜
        distances, indices = faiss_index.search(query_array, k)
        
        # 3. ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ê´€ë ¨ ë¬¸ì„œ ì¶”ì¶œ
        retrieved_passages = []
        for i, idx in enumerate(indices[0]):
            # ìœ íš¨í•œ ì¸ë±ìŠ¤ì¸ì§€ í™•ì¸
            if idx >= 0 and idx < len(metadata_list):
                doc_data = metadata_list[idx]
                
                # ë¬¸ì„œì—ì„œ í…ìŠ¤íŠ¸ ë‚´ìš© ì¶”ì¶œ (ë‹¤ì–‘í•œ í‚¤ í˜•íƒœ ì§€ì›)
                text_content = doc_data.get("text", doc_data.get("content", doc_data.get("passage", "")))
                
                if text_content:
                    # í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ (ë„ˆë¬´ ê¸´ ê²½ìš° 500ìë¡œ ì œí•œ)
                    limited_text = text_content[:500] + "..." if len(text_content) > 500 else text_content
                    retrieved_passages.append(limited_text)
                    
                    # ê²€ìƒ‰ í’ˆì§ˆì„ ìœ„í•œ ë””ë²„ê·¸ ì •ë³´ (ê°œë°œìš©)
                    print(f"ğŸ“„ ê²€ìƒ‰ëœ ë¬¸ì„œ {i+1}: ìœ ì‚¬ë„ ì ìˆ˜ {distances[0][i]:.4f}")
        
        # 4. ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆìœ¼ë©´ í¬ë§·íŒ…í•˜ì—¬ ë°˜í™˜
        if retrieved_passages:
            combined_content = "\n\n=== ê´€ë ¨ í•´ì„¤ ===\n\n".join(retrieved_passages)
            return f"ë²¡í„° ê²€ìƒ‰ ê²°ê³¼:\n\n{combined_content}"
        else:
            return "ê´€ë ¨ëœ í•´ì„¤ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ í‰ê°€ ê¸°ì¤€ì— ë”°ë¼ ë‹µë³€ì„ í‰ê°€í•˜ê² ìŠµë‹ˆë‹¤."
            
    except Exception as e:
        print(f"Error during retrieval: {e}")
        return f"í•´ì„¤ì„ ê²€ìƒ‰í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

# --- ì¶”ê°€ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ---

def get_vector_db_status():
    """Vector DB ìƒíƒœ í™•ì¸ìš© í•¨ìˆ˜ (ë””ë²„ê¹…/ëª¨ë‹ˆí„°ë§ìš©)"""
    status = {
        "faiss_loaded": faiss_index is not None,
        "metadata_loaded": metadata_list is not None,
        "vector_count": faiss_index.ntotal if faiss_index else 0,
        "document_count": len(metadata_list) if metadata_list else 0
    }
    return status

def reload_vector_db():
    """Vector DB ì¬ë¡œë“œ í•¨ìˆ˜ (í•„ìš”ì‹œ ì‚¬ìš©)"""
    print("ğŸ”„ Vector DB ì¬ë¡œë“œ ì¤‘...")
    load_faiss_index_and_metadata()
